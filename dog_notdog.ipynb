{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled5.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMLYV9pSZlF2HDZ8EiOU22U",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mohanrajmit/Transfer-Learning/blob/master/dog_notdog.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ySwQLZPhzzxO"
      },
      "source": [
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import joblib\n",
        "from keras.preprocessing import image\n",
        "from keras.applications import vgg16"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Xb45at4z60Y"
      },
      "source": [
        "# Path to folders with training data\n",
        "dog_path = Path(\"/content/training_data/dogs\")\n",
        "not_dog_path = Path(\"/content/training_data/not_dogs\")\n",
        "\n",
        "images = []\n",
        "labels = []\n",
        "\n",
        "# Load all the not-dog images\n",
        "for img in not_dog_path.glob(\"*.png\"):\n",
        "    # Load the image from disk\n",
        "    img = image.load_img(img)\n",
        "\n",
        "    # Convert the image to a numpy array\n",
        "    image_array = image.img_to_array(img)\n",
        "\n",
        "    # Add the image to the list of images\n",
        "    images.append(image_array)\n",
        "\n",
        "    # For each 'not dog' image, the expected value should be 0\n",
        "    labels.append(0)\n",
        "\n",
        "# Load all the dog images\n",
        "for img in dog_path.glob(\"*.png\"):\n",
        "    # Load the image from disk\n",
        "    img = image.load_img(img)\n",
        "\n",
        "    # Convert the image to a numpy array\n",
        "    image_array = image.img_to_array(img)\n",
        "\n",
        "    # Add the image to the list of images\n",
        "    images.append(image_array)\n",
        "\n",
        "    # For each 'dog' image, the expected value should be 1\n",
        "    labels.append(1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mg9ZmkLE0unG",
        "outputId": "f0ffe39b-3082-4b3d-9e6e-54ebd4be111e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Create a single numpy array with all the images we loaded\n",
        "x_train = np.array(images)\n",
        "\n",
        "# Also convert the labels to a numpy array\n",
        "y_train = np.array(labels)\n",
        "\n",
        "# Normalize image data to 0-to-1 range\n",
        "x_train = vgg16.preprocess_input(x_train)\n",
        "\n",
        "# Load a pre-trained neural network to use as a feature extractor\n",
        "pretrained_nn = vgg16.VGG16(weights='imagenet', include_top=False, input_shape=(64, 64, 3))\n",
        "\n",
        "# Extract features for each image (all in one pass)\n",
        "features_x = pretrained_nn.predict(x_train)\n",
        "\n",
        "# Save the array of extracted features to a file\n",
        "joblib.dump(features_x, \"x_train.dat\")\n",
        "\n",
        "# Save the matching array of expected values to a file\n",
        "joblib.dump(y_train, \"y_train.dat\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:6 out of the last 9 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f895787bc80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['y_train.dat']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ro2g7H8X1BGt"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from pathlib import Path\n",
        "import joblib"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "44It266F1LE0"
      },
      "source": [
        "# Load data set\n",
        "x_train = joblib.load(\"x_train.dat\")\n",
        "y_train = joblib.load(\"y_train.dat\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1594DMcM1Nr5"
      },
      "source": [
        "# Create a model and add layers\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Flatten(input_shape=x_train.shape[1:]))\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(\n",
        "    loss=\"binary_crossentropy\",\n",
        "    optimizer=\"adam\",\n",
        "    metrics=['accuracy']\n",
        ")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LrvVlTvA1QQV",
        "outputId": "d972273e-960e-4379-a71a-66ba63746de1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "\n",
        "# Train the model\n",
        "model.fit(\n",
        "    x_train,\n",
        "    y_train,\n",
        "    epochs=10,\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "# Save neural network structure\n",
        "model_structure = model.to_json()\n",
        "f = Path(\"model_structure.json\")\n",
        "f.write_text(model_structure)\n",
        "\n",
        "# Save neural network's trained weights\n",
        "model.save_weights(\"model_weights.h5\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 9.6800e-10 - accuracy: 1.0000\n",
            "Epoch 2/10\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 5.3702e-17 - accuracy: 1.0000\n",
            "Epoch 3/10\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 1.2398e-13 - accuracy: 1.0000\n",
            "Epoch 4/10\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 4.1851e-19 - accuracy: 1.0000\n",
            "Epoch 5/10\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 1.1668e-14 - accuracy: 1.0000\n",
            "Epoch 6/10\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 2.7599e-14 - accuracy: 1.0000\n",
            "Epoch 7/10\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 1.9115e-07 - accuracy: 1.0000\n",
            "Epoch 8/10\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 1.2621e-13 - accuracy: 1.0000\n",
            "Epoch 9/10\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 3.8170e-14 - accuracy: 1.0000\n",
            "Epoch 10/10\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 1.1897e-12 - accuracy: 1.0000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BJvctO8O1UHQ"
      },
      "source": [
        "from keras.models import model_from_json\n",
        "from pathlib import Path\n",
        "from keras.preprocessing import image\n",
        "import numpy as np\n",
        "from keras.applications import vgg16"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1_1SCpj01ZXm"
      },
      "source": [
        "# Load the json file that contains the model's structure\n",
        "f = Path(\"model_structure.json\")\n",
        "model_structure = f.read_text()\n",
        "\n",
        "# Recreate the Keras model object from the json data\n",
        "model = model_from_json(model_structure)\n",
        "\n",
        "# Re-load the model's trained weights\n",
        "model.load_weights(\"model_weights.h5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ioqnglzB1ciS"
      },
      "source": [
        "# Load an image file to test, resizing it to 64x64 pixels (as required by this model)\n",
        "img = image.load_img(\"/content/00001.png\", target_size=(64, 64))\n",
        "\n",
        "# Convert the image to a numpy array\n",
        "image_array = image.img_to_array(img)\n",
        "\n",
        "# Add a forth dimension to the image (since Keras expects a bunch of images, not a single image)\n",
        "images = np.expand_dims(image_array, axis=0)\n",
        "\n",
        "# Normalize the data\n",
        "images = vgg16.preprocess_input(images)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UnV9qRHr1f0r",
        "outputId": "96b03ec7-248e-4577-b6f0-a8d49cef8211",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "\n",
        "# Use the pre-trained neural network to extract features from our test image (the same way we did to train the model)\n",
        "feature_extraction_model = vgg16.VGG16(weights='imagenet', include_top=False, input_shape=(64, 64, 3))\n",
        "features = feature_extraction_model.predict(images)\n",
        "\n",
        "# Given the extracted features, make a final prediction using our own model\n",
        "results = model.predict(features)\n",
        "\n",
        "# Since we are only testing one image with possible class, we only need to check the first result's first element\n",
        "single_result = results[0][0]\n",
        "\n",
        "# Print the result\n",
        "print(\"Likelihood that this image contains a dog: {}%\".format(int(single_result * 100)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:8 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f89554bb268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "Likelihood that this image contains a dog: 100%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FQrXRMut8czQ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}